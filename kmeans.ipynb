{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:01:23.994610Z",
     "start_time": "2025-05-28T12:01:23.600801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import xlsxwriter\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from awesome_doanh_ml.helper import cal_num_combinations, flat_arr, cal_NC1_twoSet\n",
    "from awesome_doanh_ml.utils.numpy_utils import TwoDIndexObject"
   ],
   "id": "53288a39c16355d1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:01:26.516444Z",
     "start_time": "2025-05-28T12:01:25.710987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fetch dataset\n",
    "iris = fetch_ucirepo(id=53)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = iris.data.features\n",
    "y = iris.data.targets\n",
    "X_columns = np.array(list(X.columns))\n",
    "\n",
    "# number of clusters\n",
    "cluster_nums = [2,3,4]\n",
    "\n",
    "# metadata\n",
    "print(iris.metadata)\n",
    "\n",
    "# variable information\n",
    "print(iris.variables)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X)\n",
    "predictions = kmeans.labels_\n",
    "kmeans.cluster_centers_"
   ],
   "id": "745f3ff7c96040ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T17:51:35.173638Z",
     "start_time": "2025-05-24T17:51:35.099186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cluster_dfs = []\n",
    "for inx in range(kmeans.n_clusters):\n",
    "    cluster_dfs.append(pd.DataFrame(columns=['sepal length', 'sepal width']).T)\n",
    "\n",
    "for inx, row in enumerate(X.iterrows()):\n",
    "    if inx == 0:\n",
    "        cluster_dfs[predictions[inx]] = pd.concat([cluster_dfs[predictions[inx]].T,row[1].to_frame().T])\n",
    "    else:\n",
    "        cluster_dfs[predictions[inx]] = pd.concat([cluster_dfs[predictions[inx]],row[1].to_frame().T])"
   ],
   "id": "58db89436627d0d2",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = X.loc[0]\n",
    "b = X.loc[5]\n",
    "c = pd.concat([a.to_frame().T,b.to_frame().T])"
   ],
   "id": "cad35a7872f44056"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = cluster_dfs[0]['sepal length'].values\n",
    "y = cluster_dfs[0]['sepal width'].values"
   ],
   "id": "bb4216658025a38a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for inx, cluster_df in enumerate(cluster_dfs):\n",
    "    x = cluster_dfs[inx]['sepal length'].values\n",
    "    y = cluster_dfs[inx]['sepal width'].values\n",
    "    plt.scatter(x, y, label=f'cluster {inx}')\n",
    "    plt.xlabel('sepal length')\n",
    "    plt.ylabel('sepal width')\n",
    "    plt.legend()"
   ],
   "id": "a8db9574e1419e43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(silhouette_score(X, predictions))\n",
    "print(davies_bouldin_score(X, predictions))"
   ],
   "id": "7235b614f866f7a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ModelMetrics:\n",
    "    def __init__(self, db_scores, si_scores, db_mean, si_mean, db_dev, si_dev):\n",
    "        self.db_scores = db_scores\n",
    "        self.si_scores = si_scores\n",
    "        self.db_mean = db_mean\n",
    "        self.si_mean = si_mean\n",
    "        self.db_dev = db_dev\n",
    "        self.si_dev = si_dev"
   ],
   "id": "df591d1e88c81d37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_evalMetrics_to_excel(self):\n",
    "        workbook = xlsxwriter.Workbook(\"Result.xlsx\")\n",
    "\n",
    "        for inx, model_metrics in enumerate(self.model_metrics_s):\n",
    "\n",
    "            worksheet_fold = workbook.add_worksheet(model_metrics.model.name)\n",
    "\n",
    "            row = 1\n",
    "\n",
    "            worksheet_fold.write(0, 0, f\"Fold number\")\n",
    "            worksheet_fold.write(0, 1, f\"Accuracy score\")\n",
    "\n",
    "            for iny, mse in enumerate(model_metrics.acc_scores):\n",
    "                worksheet_fold.write(row, 0, f\"{iny}\")\n",
    "                worksheet_fold.write(row, 1, f\"{mse}\")\n",
    "                row += 1\n",
    "\n",
    "            worksheet_fold.write(row, 0, f\"Average value: {model_metrics.acc_mean}\")\n",
    "            row += 1\n",
    "            worksheet_fold.write(row, 0, f\"Standard Derivation: {model_metrics.acc_dev}\")\n",
    "            row += 1\n",
    "\n",
    "            row += 3\n",
    "\n",
    "            worksheet_fold.write(row, 0, f\"Fold number\")\n",
    "            worksheet_fold.write(row, 1, f\"F1 Score\")\n",
    "\n",
    "            row += 1\n",
    "\n",
    "            for iny, mse in enumerate(model_metrics.f1_scores):\n",
    "                worksheet_fold.write(row, 0, f\"{iny}\")\n",
    "                worksheet_fold.write(row, 1, f\"{mse}\")\n",
    "                row += 1\n",
    "\n",
    "            worksheet_fold.write(row, 0, f\"Average value: {model_metrics.f1_mean}\")\n",
    "            row += 1\n",
    "            worksheet_fold.write(row, 0, f\"Standard Derivation: {model_metrics.f1_dev}\")\n",
    "            row += 1\n",
    "\n",
    "            row += 3\n",
    "\n",
    "        workbook.close()\n",
    "\n",
    "        return"
   ],
   "id": "bc66db0960ee5c83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:02:27.532878Z",
     "start_time": "2025-05-28T12:02:27.524649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Prepare column combinations\n",
    "column_combination_indexes = cal_num_combinations(len(X.columns))"
   ],
   "id": "8e0f3a1ce4a924ba",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#One cluster with combination of features\n",
    "for inx, indexes in enumerate(column_combination_indexes_flatten):\n",
    "    kmeans = KMeans(n_clusters=3, n_init=\"auto\")\n",
    "    column_names = list(X_columns[list(indexes)])\n",
    "    data_prepared = X[column_names]\n",
    "    print(f'Columns; {data_prepared.columns.values}')\n",
    "    kmeans.fit(X)\n",
    "    predictions = kmeans.labels_\n",
    "    print(silhouette_score(X, predictions))\n",
    "    print(davies_bouldin_score(X, predictions))"
   ],
   "id": "1bca3fcd01b222ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:02:29.197610Z",
     "start_time": "2025-05-28T12:02:28.757223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kmean_result = TwoDIndexObject(cluster_nums, column_combination_indexes, columns = ['sil_score', 'db_score'])\n",
    "kmean_result.twod_df.sort_index()\n",
    "\n",
    "kmean_result.assign_value(2, (0, 1), 10)\n",
    "kmean_result.twod_df.loc[pd.IndexSlice[2, (0,1)], :] = 4\n",
    "for inx, cluster_num in enumerate(cluster_nums):\n",
    "    for iny, column_combination_index in enumerate(column_combination_indexes):\n",
    "        kmeans = KMeans(n_clusters=cluster_num, n_init=\"auto\")\n",
    "        column_names = list(X_columns[list(column_combination_index)])\n",
    "        data_prepared = X[column_names]\n",
    "        print(f'Columns; {data_prepared.columns.values}')\n",
    "        kmeans.fit(X)\n",
    "        predictions = kmeans.labels_\n",
    "        sil_score = silhouette_score(X, predictions)\n",
    "        db_score = davies_bouldin_score(X, predictions)\n",
    "        kmean_result.assign_value(cluster_num, column_combination_index, [sil_score, db_score])\n",
    "# print(kmean_result.loc(2,(0, 1)))jk"
   ],
   "id": "73b212cb495b5e4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns; ['sepal length']\n",
      "Columns; ['sepal width']\n",
      "Columns; ['petal length']\n",
      "Columns; ['petal width']\n",
      "Columns; ['sepal length' 'sepal width']\n",
      "Columns; ['sepal length' 'petal length']\n",
      "Columns; ['sepal length' 'petal width']\n",
      "Columns; ['sepal width' 'petal length']\n",
      "Columns; ['sepal width' 'petal width']\n",
      "Columns; ['petal length' 'petal width']\n",
      "Columns; ['sepal length' 'sepal width' 'petal length']\n",
      "Columns; ['sepal length' 'sepal width' 'petal width']\n",
      "Columns; ['sepal length' 'petal length' 'petal width']\n",
      "Columns; ['sepal width' 'petal length' 'petal width']\n",
      "Columns; ['sepal length']\n",
      "Columns; ['sepal width']\n",
      "Columns; ['petal length']\n",
      "Columns; ['petal width']\n",
      "Columns; ['sepal length' 'sepal width']\n",
      "Columns; ['sepal length' 'petal length']\n",
      "Columns; ['sepal length' 'petal width']\n",
      "Columns; ['sepal width' 'petal length']\n",
      "Columns; ['sepal width' 'petal width']\n",
      "Columns; ['petal length' 'petal width']\n",
      "Columns; ['sepal length' 'sepal width' 'petal length']\n",
      "Columns; ['sepal length' 'sepal width' 'petal width']\n",
      "Columns; ['sepal length' 'petal length' 'petal width']\n",
      "Columns; ['sepal width' 'petal length' 'petal width']\n",
      "Columns; ['sepal length']\n",
      "Columns; ['sepal width']\n",
      "Columns; ['petal length']\n",
      "Columns; ['petal width']\n",
      "Columns; ['sepal length' 'sepal width']\n",
      "Columns; ['sepal length' 'petal length']\n",
      "Columns; ['sepal length' 'petal width']\n",
      "Columns; ['sepal width' 'petal length']\n",
      "Columns; ['sepal width' 'petal width']\n",
      "Columns; ['petal length' 'petal width']\n",
      "Columns; ['sepal length' 'sepal width' 'petal length']\n",
      "Columns; ['sepal length' 'sepal width' 'petal width']\n",
      "Columns; ['sepal length' 'petal length' 'petal width']\n",
      "Columns; ['sepal width' 'petal length' 'petal width']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "X = np.arange(0, math.pi*2, 0.05)\n",
    "\n",
    "# Using built-in trigonometric function we can directly plot\n",
    "# the given cosine wave for the given angles\n",
    "Y1 = np.sin(X)\n",
    "Y2 = np.cos(X)\n",
    "Y3 = np.tan(X)\n",
    "Y4 = np.tanh(X)\n",
    "\n",
    "# Initialise the subplot function using number of rows and columns\n",
    "# figure, axis = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "figure, axis = plt.subplots(2, 2)\n",
    "\n",
    "# For Sine Function\n",
    "axis[0, 0].plot(X, Y1, label='test label')\n",
    "axis[0, 0].set_title(\"Sine Function\")\n",
    "axis[0, 0].legend(loc='upper right')\n",
    "axis[0, 0].grid('on')\n",
    "plt.setp(axis[0, 0].get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "\n",
    "# For Cosine Function\n",
    "axis[0, 1].plot(X, Y2, label='test label')\n",
    "axis[0, 1].set_title(\"Cosine Function\")\n",
    "plt.setp(axis[0, 1].get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "\n",
    "# For Tangent Function\n",
    "axis[1, 0].plot(X, Y3, label='test label')\n",
    "axis[1, 0].set_title(\"Tangent Function\")\n",
    "plt.setp(axis[1, 0].get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "\n",
    "# For Tanh Function\n",
    "axis[1, 1].plot(X, Y4, label='test label')\n",
    "axis[1, 1].set_title(\"Tanh Function\")\n",
    "plt.setp(axis[1, 1].get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "\n",
    "# Combine all the operations and display\n",
    "figure.tight_layout()"
   ],
   "id": "bd4434820944e901"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
